{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里PAGA环境比较老，本地不好配置，启动docker，\n",
    "\n",
    "```\n",
    "docker run -it \\\n",
    "    -v /home/huang/RCode/scrna_tools/dynverse_reproduce/ti_paga:/ti/workspace \\\n",
    "    --entrypoint /bin/bash \\\n",
    "    dynverse/ti_paga:v0.9.9.05\n",
    "```\n",
    "\n",
    "附加VSCode，安装python，jupyter插件,调试后续的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据输入和参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynclipy\n",
    "\n",
    "\n",
    "# 参数部分\n",
    "tmp_dir = \"tmp\"\n",
    "input_h5 = f\"{tmp_dir}/input.h5\"\n",
    "output_h5 = f\"{tmp_dir}/output.h5\"\n",
    "# args = f\"--dataset {input_h5} --output output_h5\"\n",
    "args = [\"--dataset\", input_h5, \"--output\", output_h5]\n",
    "\n",
    "# 方法描述定义部分\n",
    "definition_location = \"definition.yml\" \n",
    "\n",
    "task = dynclipy.main(args, definition_location) # 内部其实是调用了R的代码\n",
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "轨迹推断方法执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid errors due to no $DISPLAY environment variable available when running sc.pl.paga\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "\n",
    "# import scanpy.api as sc\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import numba\n",
    "import warnings\n",
    "\n",
    "import time\n",
    "checkpoints = {}\n",
    "\n",
    "#   ____________________________________________________________________________\n",
    "#   Load data                                                               ####\n",
    "#  NOTE: 导入数据，从task转化为表达矩阵，可以学习一下，后续可能是需要这里的task wrapper与AnnData融合\n",
    "\n",
    "\n",
    "counts = task[\"counts\"]\n",
    "\n",
    "parameters = task[\"parameters\"]\n",
    "\n",
    "start_id = task[\"priors\"][\"start_id\"]\n",
    "if isinstance(start_id, list):\n",
    "  start_id = start_id[0]\n",
    "\n",
    "if \"groups_id\" in task[\"priors\"]:\n",
    "  groups_id = task[\"priors\"]['groups_id']\n",
    "else:\n",
    "  groups_id = None\n",
    "\n",
    "# create dataset\n",
    "if groups_id is not None:\n",
    "  obs = pd.DataFrame(groups_id)\n",
    "  obs.index = groups_id[\"cell_id\"] # 细胞ID\n",
    "  obs[\"louvain\"] = obs[\"group_id\"].astype(\"category\") # 细胞聚类结果, 后续在AnnData数据上关于细胞聚类的操作都是基于lovain的\n",
    "  adata = anndata.AnnData(counts)\n",
    "  adata.obs = obs\n",
    "else:\n",
    "  adata = anndata.AnnData(counts)\n",
    "\n",
    "checkpoints[\"method_afterpreproc\"] = time.time()\n",
    "\n",
    "#   ____________________________________________________________________________\n",
    "#   Basic preprocessing                                                     ####\n",
    "#  NOTE: 基础的预处理，加了很多日志\n",
    "\n",
    "# normalisation & filtering\n",
    "if counts.shape[1] < 100 and parameters[\"filter_features\"]:\n",
    "  print(\"You have less than 100 features, but the filter_features parameter is true. This will likely result in an error. Disable filter_features to avoid this\")\n",
    "\n",
    "if parameters[\"filter_features\"]:\n",
    "  n_top_genes = min(2000, counts.shape[1])\n",
    "  sc.pp.recipe_zheng17(adata, n_top_genes=n_top_genes)\n",
    "\n",
    "# precalculating some dimensionality reductions\n",
    "sc.tl.pca(adata, n_comps=parameters[\"n_comps\"])\n",
    "with warnings.catch_warnings():\n",
    "  warnings.simplefilter('ignore', numba.errors.NumbaDeprecationWarning)\n",
    "  sc.pp.neighbors(adata, n_neighbors=parameters[\"n_neighbors\"])\n",
    "\n",
    "# denoise the graph by recomputing it in the first few diffusion components\n",
    "if parameters[\"n_dcs\"] != 0:\n",
    "  sc.tl.diffmap(adata, n_comps=parameters[\"n_dcs\"])\n",
    "\n",
    "#   ____________________________________________________________________________\n",
    "#   Cluster, infer trajectory, infer pseudotime, compute dimension reduction ###\n",
    "#  NOTE: 聚类、轨迹推断、计算降维\n",
    "\n",
    "# add grouping if not provided\n",
    "if groups_id is None:\n",
    "  sc.tl.louvain(adata, resolution=parameters[\"resolution\"])\n",
    "\n",
    "# run paga\n",
    "sc.tl.paga(adata)\n",
    "\n",
    "# compute a layout for the paga graph\n",
    "# - this simply uses a Fruchterman-Reingold layout, a tree layout or any other\n",
    "#   popular graph layout is also possible\n",
    "# - to obtain a clean visual representation, one can discard low-confidence edges\n",
    "#   using the parameter threshold\n",
    "sc.pl.paga(adata, threshold=0.01, layout='fr', show=False)\n",
    "\n",
    "# run dpt for pseudotime information that is overlayed with paga\n",
    "adata.uns['iroot'] = np.where(adata.obs.index == start_id)[0][0]\n",
    "if parameters[\"n_dcs\"] == 0:\n",
    "  sc.tl.diffmap(adata)\n",
    "sc.tl.dpt(adata, n_dcs = min(adata.obsm['X_diffmap'].shape[1], 10))\n",
    "\n",
    "# run umap for a dimension-reduced embedding, use the positions of the paga\n",
    "# graph to initialize this embedding\n",
    "if parameters[\"embedding_type\"] == 'umap':\n",
    "  sc.tl.umap(adata, init_pos='paga')\n",
    "  dimred_name = 'X_umap'\n",
    "else:\n",
    "  sc.tl.draw_graph(adata, init_pos='paga')\n",
    "  dimred_name = \"X_draw_graph_\" + parameters[\"embedding_type\"]\n",
    "\n",
    "checkpoints[\"method_aftermethod\"] = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================louvain======================\n",
      "1_iN1_C01    3\n",
      "1_iN1_C02    3\n",
      "1_iN1_C03    3\n",
      "1_iN1_C04    0\n",
      "1_iN1_C05    0\n",
      "Name: louvain, dtype: category\n",
      "Categories (6, object): [0, 1, 2, 3, 4, 5]\n",
      "==================dpt pseudotime==================\n",
      "1_iN1_C01    0.000000\n",
      "1_iN1_C02    0.024606\n",
      "1_iN1_C03    0.045618\n",
      "1_iN1_C04    0.810991\n",
      "1_iN1_C05    0.616293\n",
      "Name: dpt_pseudotime, dtype: float32\n",
      "===============paga connectivities================\n",
      "array([[0.          , 0.0013689134, 0.0405245574, 0.0877420846,\n",
      "        0.0169298271, 0.0044600082],\n",
      "       [0.0013689134, 0.          , 0.1311088621, 0.0265885105,\n",
      "        0.0451462056, 0.0178400329],\n",
      "       [0.0405245574, 0.1311088621, 0.          , 0.2268733422,\n",
      "        0.235850005 , 0.2718298109],\n",
      "       [0.0877420846, 0.0265885105, 0.2268733422, 0.          ,\n",
      "        0.6686196457, 0.          ],\n",
      "       [0.0169298271, 0.0451462056, 0.235850005 , 0.6686196457,\n",
      "        0.          , 0.          ],\n",
      "       [0.0044600082, 0.0178400329, 0.2718298109, 0.          ,\n",
      "        0.          , 0.          ]])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "# 主要结果\n",
    "print(\"louvain\".center(50, '='))\n",
    "pprint.pprint(adata.obs[\"louvain\"].head(5))\n",
    "print(\"dpt pseudotime\".center(50, '='))\n",
    "pprint.pprint(adata.obs[\"dpt_pseudotime\"].head(5))\n",
    "print(\"paga connectivities\".center(50, '='))\n",
    "pprint.pprint(adata.uns[\"paga\"][\"connectivities\"].A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ____________________________________________________________________________\n",
    "#   Process & save output                                                   ####\n",
    "#  NOTE: 至此完成了的轨迹推断任务的操作，后续即是结果的封装\n",
    "\n",
    "# grouping\n",
    "grouping = pd.DataFrame({\"cell_id\": adata.obs.index, \"group_id\": adata.obs.louvain})\n",
    "\n",
    "# milestone network(n_louvain, n_louvain)\n",
    "# 细胞聚类间的距离矩阵，宽数据转化为常数\n",
    "milestone_network = pd.DataFrame(\n",
    "  np.triu(adata.uns[\"paga\"][\"connectivities\"].todense(), k = 0),\n",
    "  index=adata.obs.louvain.cat.categories,\n",
    "  columns=adata.obs.louvain.cat.categories\n",
    ").stack().reset_index()\n",
    "milestone_network.columns = [\"from\", \"to\", \"length\"]\n",
    "milestone_network = milestone_network.query(\"length >= \" + str(parameters[\"connectivity_cutoff\"])).reset_index(drop=True) # 距离矩阵设置阈值阶段\n",
    "milestone_network[\"directed\"] = False\n",
    "\n",
    "# dimred， (n_obs, 2)\n",
    "dimred = pd.DataFrame([x for x in adata.obsm[dimred_name].T]).T\n",
    "dimred.columns = [\"comp_\" + str(i+1) for i in range(dimred.shape[1])]\n",
    "dimred[\"cell_id\"] = adata.obs.index\n",
    "\n",
    "# branch progressions: the scaled dpt_pseudotime within every cluster，(n_obs, 3)\n",
    "branch_progressions = adata.obs\n",
    "# 每个细胞聚类为一个branch\n",
    "branch_progressions[\"dpt_pseudotime\"] = branch_progressions[\"dpt_pseudotime\"].replace([np.inf, -np.inf], 1) # replace unreachable pseudotime with maximal pseudotime # 排除异常值\n",
    "branch_progressions[\"percentage\"] = branch_progressions.groupby(\"louvain\")[\"dpt_pseudotime\"].apply(lambda x: (x-x.min())/(x.max() - x.min())).fillna(0.5) # 最大最小归一化\n",
    "branch_progressions[\"cell_id\"] = adata.obs.index\n",
    "branch_progressions[\"branch_id\"] = branch_progressions[\"louvain\"].astype(np.str)\n",
    "branch_progressions = branch_progressions[[\"cell_id\", \"branch_id\", \"percentage\"]] # 只保留这三列\n",
    "\n",
    "# branches，(n_obs, 3):\n",
    "# - length = difference between max and min dpt_pseudotime within every cluster # 长度为伪时间的跨度\n",
    "# - directed = not yet correctly inferred  # 方向至今还没有正确推断出来\n",
    "branches = adata.obs.groupby(\"louvain\").apply(lambda x: x[\"dpt_pseudotime\"].max() - x[\"dpt_pseudotime\"].min()).reset_index()\n",
    "branches.columns = [\"branch_id\", \"length\"]\n",
    "branches[\"branch_id\"] = branches[\"branch_id\"].astype(np.str)\n",
    "branches[\"directed\"] = True\n",
    "\n",
    "# branch network: determine order of from and to based on difference in average pseudotime\n",
    "# 添加带方向的网络结构\n",
    "branch_network = milestone_network[[\"from\", \"to\"]]\n",
    "average_pseudotime = adata.obs.groupby(\"louvain\")[\"dpt_pseudotime\"].mean()\n",
    "for i, (branch_from, branch_to) in enumerate(zip(branch_network[\"from\"], branch_network[\"to\"])):\n",
    "  if average_pseudotime[branch_from] > average_pseudotime[branch_to]:\n",
    "    branch_network.at[i, \"to\"] = branch_from\n",
    "    branch_network.at[i, \"from\"] = branch_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py:62: UserWarning: Error while trying to convert the column \"from\". Fall back to string conversion. The error is: <class 'numpy.str_'>\n",
      "  % (name, str(e)))\n",
      "/usr/local/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py:62: UserWarning: Error while trying to convert the column \"to\". Fall back to string conversion. The error is: <class 'numpy.str_'>\n",
      "  % (name, str(e)))\n"
     ]
    }
   ],
   "source": [
    "# 在监视窗口实时查看R中的对象, 使用ro.globalenv[dataset.id]\n",
    "dataset = dynclipy.wrap_data(cell_ids = adata.obs.index)\n",
    "dataset.add_branch_trajectory(\n",
    "  grouping = grouping,\n",
    "  branch_progressions = branch_progressions,\n",
    "  branches = branches,\n",
    "  branch_network = branch_network\n",
    ") # 看看Python里的add_branch_trajectory是如何工作的\n",
    "dataset.add_dimred(dimred = dimred)\n",
    "dataset.add_timings(checkpoints)\n",
    "\n",
    "# 额外添加的add之前的数据,方便放到R里调试\n",
    "before_add = dict(\n",
    "    # wrap_add\n",
    "    cell_ids = adata.obs.index,\n",
    "    # add_branch_trajectory(主要调试目标)\n",
    "    grouping = grouping,\n",
    "    branch_progressions = branch_progressions,\n",
    "    branches = branches,\n",
    "    branch_network = branch_network,\n",
    "    # add_dimred\n",
    "    dimred = dimred,\n",
    "    # checkpoints\n",
    "    checkpoints = checkpoints\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "ro.globalenv[\"before_add\"] = ro.ListVector([[name, x] for name, x in before_add.items()]) # 待添加的内容转换到R变量里\n",
    "ro.r(f\"{dataset.id}$before_add = before_add\") # 调用R修改\n",
    "\n",
    "dataset.write_output(task[\"output\"])\n",
    "\n",
    "# dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydynverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
